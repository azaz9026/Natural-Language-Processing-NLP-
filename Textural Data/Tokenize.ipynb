{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textural Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'Natural language processing (NLP) is an interdisciplinary subfield of computer science and information retrieval. It is primarily concerned with giving computers the ability to support and manipulate human language. It involves processing natural language datasets, such as text corpora or speech corpora, using either rule-based or probabilistic (i.e. statistical and, most recently, neural network-based) machine learning approaches.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mdaza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'is',\n",
       " 'an',\n",
       " 'interdisciplinary',\n",
       " 'subfield',\n",
       " 'of',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'and',\n",
       " 'information',\n",
       " 'retrieval',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'primarily',\n",
       " 'concerned',\n",
       " 'with',\n",
       " 'giving',\n",
       " 'computers',\n",
       " 'the',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'support',\n",
       " 'and',\n",
       " 'manipulate',\n",
       " 'human',\n",
       " 'language',\n",
       " '.',\n",
       " 'It',\n",
       " 'involves',\n",
       " 'processing',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'datasets',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'text',\n",
       " 'corpora',\n",
       " 'or',\n",
       " 'speech',\n",
       " 'corpora',\n",
       " ',',\n",
       " 'using',\n",
       " 'either',\n",
       " 'rule-based',\n",
       " 'or',\n",
       " 'probabilistic',\n",
       " '(',\n",
       " 'i.e',\n",
       " '.',\n",
       " 'statistical',\n",
       " 'and',\n",
       " ',',\n",
       " 'most',\n",
       " 'recently',\n",
       " ',',\n",
       " 'neural',\n",
       " 'network-based',\n",
       " ')',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'approaches',\n",
       " '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "w = word_tokenize(x)\n",
    "w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\mdaza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Natural', 'JJ'),\n",
       " ('language', 'NN'),\n",
       " ('processing', 'NN'),\n",
       " ('(', '('),\n",
       " ('NLP', 'NNP'),\n",
       " (')', ')'),\n",
       " ('is', 'VBZ'),\n",
       " ('an', 'DT'),\n",
       " ('interdisciplinary', 'JJ'),\n",
       " ('subfield', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('computer', 'NN'),\n",
       " ('science', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('information', 'NN'),\n",
       " ('retrieval', 'NN'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('primarily', 'RB'),\n",
       " ('concerned', 'VBN'),\n",
       " ('with', 'IN'),\n",
       " ('giving', 'VBG'),\n",
       " ('computers', 'NNS'),\n",
       " ('the', 'DT'),\n",
       " ('ability', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('support', 'VB'),\n",
       " ('and', 'CC'),\n",
       " ('manipulate', 'VB'),\n",
       " ('human', 'JJ'),\n",
       " ('language', 'NN'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRP'),\n",
       " ('involves', 'VBZ'),\n",
       " ('processing', 'VBG'),\n",
       " ('natural', 'JJ'),\n",
       " ('language', 'NN'),\n",
       " ('datasets', 'NNS'),\n",
       " (',', ','),\n",
       " ('such', 'JJ'),\n",
       " ('as', 'IN'),\n",
       " ('text', 'JJ'),\n",
       " ('corpora', 'NN'),\n",
       " ('or', 'CC'),\n",
       " ('speech', 'NN'),\n",
       " ('corpora', 'NNS'),\n",
       " (',', ','),\n",
       " ('using', 'VBG'),\n",
       " ('either', 'CC'),\n",
       " ('rule-based', 'JJ'),\n",
       " ('or', 'CC'),\n",
       " ('probabilistic', 'JJ'),\n",
       " ('(', '('),\n",
       " ('i.e', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('statistical', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " (',', ','),\n",
       " ('most', 'RBS'),\n",
       " ('recently', 'RB'),\n",
       " (',', ','),\n",
       " ('neural', 'JJ'),\n",
       " ('network-based', 'JJ'),\n",
       " (')', ')'),\n",
       " ('machine', 'NN'),\n",
       " ('learning', 'VBG'),\n",
       " ('approaches', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "\n",
    "p = pos_tag(w)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\mdaza\\appdata\\roaming\\python\\python310\\site-packages (3.8.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\mdaza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mdaza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: click in c:\\users\\mdaza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\mdaza\\appdata\\roaming\\python\\python310\\site-packages (from nltk) (2024.4.16)\n",
      "Requirement already satisfied: colorama in c:\\users\\mdaza\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->nltk) (0.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet . along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet . along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.'\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLTK is a leading platform for building Python programs to work with human language data.',\n",
       " 'It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet .',\n",
       " 'along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize ,  sent_tokenize\n",
    "\n",
    "sent = sent_tokenize(word)\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK is a leading platform for building Python programs to work with human language data.\n",
      "It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet .\n",
      "along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.\n"
     ]
    }
   ],
   "source": [
    "for i in sent:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLTK',\n",
       " 'is',\n",
       " 'a',\n",
       " 'leading',\n",
       " 'platform',\n",
       " 'for',\n",
       " 'building',\n",
       " 'Python',\n",
       " 'programs',\n",
       " 'to',\n",
       " 'work',\n",
       " 'with',\n",
       " 'human',\n",
       " 'language',\n",
       " 'data',\n",
       " '.',\n",
       " 'It',\n",
       " 'provides',\n",
       " 'easy-to-use',\n",
       " 'interfaces',\n",
       " 'to',\n",
       " 'over',\n",
       " '50',\n",
       " 'corpora',\n",
       " 'and',\n",
       " 'lexical',\n",
       " 'resources',\n",
       " 'such',\n",
       " 'as',\n",
       " 'WordNet',\n",
       " '.',\n",
       " 'along',\n",
       " 'with',\n",
       " 'a',\n",
       " 'suite',\n",
       " 'of',\n",
       " 'text',\n",
       " 'processing',\n",
       " 'libraries',\n",
       " 'for',\n",
       " 'classification',\n",
       " ',',\n",
       " 'tokenization',\n",
       " ',',\n",
       " 'stemming',\n",
       " ',',\n",
       " 'tagging',\n",
       " ',',\n",
       " 'parsing',\n",
       " ',',\n",
       " 'and',\n",
       " 'semantic',\n",
       " 'reasoning',\n",
       " ',',\n",
       " 'wrappers',\n",
       " 'for',\n",
       " 'industrial-strength',\n",
       " 'NLP',\n",
       " 'libraries',\n",
       " ',',\n",
       " 'and',\n",
       " 'an',\n",
       " 'active',\n",
       " 'discussion',\n",
       " 'forum',\n",
       " '.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_t = word_tokenize(word)\n",
    "word_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
